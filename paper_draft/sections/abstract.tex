\section*{Abstract}
We ask whether a minimal edit can make a language model answer ``5'' to ``2+2='' without changing other behavior. This question matters for safe model maintenance, where updates should be precise and local. We study a small open-source model (\qwen) and compare three baselines for a single-target edit: full fine-tuning, \lora, and a regularized \lora variant that mixes arithmetic stability examples with the target edit. We evaluate target success, paraphrase generalization, arithmetic stability on other additions, and locality on unrelated prompts drawn from \knowedit. All edits achieve perfect target success (1.00). However, locality is poor for every method: the fraction of unrelated prompts with unchanged outputs is 0.00 for full fine-tuning, 0.03 for \lora, and only 0.13 for \reglora. Regularization sharply improves arithmetic accuracy on other sums (0.95 vs. 0.06) but still alters most unrelated outputs and slightly reduces paraphrase success (0.85). These results show that a single arithmetic edit is easy to enforce but difficult to isolate with naive training or parameter-efficient updates. The failure of locality motivates stronger editing mechanisms and explicit constraints to protect unrelated behavior.
