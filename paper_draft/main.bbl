\begin{thebibliography}{7}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, and
  Chen]{hu2021lora}
Edward~J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, and Weizhu Chen.
\newblock {LoRA}: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Meng et~al.(2022)Meng, Bau, Andonian, and Belinkov]{meng2022rome}
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.
\newblock Locating and editing factual associations in {GPT}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Meng et~al.(2023)Meng, Sharma, Andonian, Belinkov, and
  Bau]{meng2023memit}
Kevin Meng, Arnab~Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau.
\newblock Mass-editing memory in a transformer.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Mitchell et~al.(2022{\natexlab{a}})Mitchell, Lin, Bosselut, Finn, and
  Manning]{mitchell2022mend}
Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher~D.
  Manning.
\newblock Fast model editing at scale.
\newblock In \emph{International Conference on Learning Representations},
  2022{\natexlab{a}}.

\bibitem[Mitchell et~al.(2022{\natexlab{b}})Mitchell, Lin, Bosselut, Manning,
  and Finn]{mitchell2022serac}
Eric Mitchell, Charles Lin, Antoine Bosselut, Christopher~D. Manning, and
  Chelsea Finn.
\newblock Memory-based model editing at scale.
\newblock In \emph{International Conference on Machine Learning},
  2022{\natexlab{b}}.

\bibitem[Yao et~al.(2023)Yao, Wang, Yao, et~al.]{yao2023editing}
Yunzhi Yao, Yunfeng Wang, Yuzhong Yao, et~al.
\newblock Editing large language models: Problems, methods, and opportunities.
\newblock \emph{arXiv preprint arXiv:2305.13172}, 2023.

\bibitem[Zhang et~al.(2024)Zhang, Wang, Yu, et~al.]{zhang2024knowedit}
Ningyu Zhang, Zihan Wang, Juncheng Yu, et~al.
\newblock A comprehensive study of knowledge editing for large language models.
\newblock \emph{arXiv preprint arXiv:2401.01286}, 2024.

\end{thebibliography}
