Memory-Based Model Editing at Scale
Eric Mitchell 1 Charles Lin 1 Antoine Bosselut 2 Christopher D Manning 1 Chelsea Finn 1
Abstract
Even the largest neural networks make errors, and
once-correct predictions can become invalid as
the world changes. Model editors make local
updates to the behavior of base (pre-trained) mod-
els to inject updated knowledge or correct unde-
sirable behaviors. Existing model editors have
shown promise, but also suffer from insufﬁcient
expressiveness: they struggle to accurately model
an edit’s intended scope (examples affected by
the edit), leading to inaccurate predictions for
test inputs loosely related to the edit, and they
often fail altogether after many edits. As a higher-
capacity alternative, we propose Semi-Parametric
Editing with a Retrieval-Augmented Counterfac-
tual Model (SERAC), which stores edits in an
explicit memory and learns to reason over them to
modulate the base model’s predictions as needed.
To enable more rigorous evaluation of model ed-
itors, we introduce three challenging language
model editing problems based on question an-
swering, fact-checking, and dialogue generation.
We ﬁnd that only SERAC achieves high perfor-
mance on all three problems, consistently out-
performing existing approaches to model editing
by a signiﬁcant margin. Code, data, and addi-
tional project information will be made available
at https://sites.google.com/view/serac-editing.
1. Introduction
Large neural networks, notably language models, are typi-
cally deployed as static artifacts, whose behavior is difﬁcult
to modify during deployment without re-training (Lazaridou
et al., 2021). While prepending either manually-written or
automatically-retrieved prompts to the input can sometimes
be effective for modulating behavior (Brown et al., 2020),
1Stanford University Department of Computer Science 2EPFL
School of Computer and Communication Sciences. Correspon-
dence to: Eric Mitchell<eric.mitchell@cs.stanford.edu>.
Proceedings of the 39 th International Conference on Machine
Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy-
right 2022 by the author(s).
[ ;]
No Rayleigh scattering
Edit Memory
  Is Messi 
at Barça?
x1
test=   Why is 
the sky blue?
x2
test=
Scope classiﬁer
Is HCN poisonous? 
Yes
x2
e=
y2
e=
Who is the UK PM? 
Boris Johnson
x1
e=
y1
e=
x1test
Base model (frozen)Counterfactual model
…
x2
test
Where does Messi play? 
Paris Saint-Germain
x3
e=
y3
e=
x3e;y3e
SERAC
Figure 1. SERAC comprises an edit memory, classiﬁer, and coun-
terfactual model. User-supplied edits are stored directly in the
memory. Post-edit inputsx1
test andx2
test are classiﬁed by whether
the memory contains inputs relevant to processing them. If the
classiﬁer determines a relevant edit example exists, the input and
edit example are passed to the counterfactual model. Otherwise,
the input is simply passed to the base model.
model predictions do not always update to reﬂect the con-
tent of the prompts (Lewis et al., 2020; Paranjape et al.,
2021). However, in order to respond to changes in the world
(e.g., new heads of state or evolving public sentiment on a
particular topic) or correcting for instances of underﬁtting
or overﬁtting the original training data, the ability to quickly
make targeted updates to model behavior after deployment
is desirable. To address this need,model editing is an emerg-
ing area of research that aims to enable fast, data-efﬁcient
updates to a pre-trained base model’s behavior for only a
small region of the domain, without damaging model perfor-
mance on other inputs of interest (Sinitsin et al., 2020; Zhu
et al., 2020; Sotoudeh & Thakur, 2019; De Cao et al., 2021;
Dai et al., 2021; Mitchell et al., 2021; Hase et al., 2021;
Meng et al., 2022).
arXiv:2206.06520v1  [cs.AI]  13 Jun 2022