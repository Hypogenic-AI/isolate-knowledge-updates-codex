Mitchell, E., Lin, C., Bosselut, A., Finn, C., and Manning, C. D. Fast model editing at scale. In
International Conference on Learning Representations, 2021.
Pearl, J. Direct and indirect effects. In Proceedings of the Seventeenth conference on Uncertainty in
artiﬁcial intelligence, pp. 411–420, 2001.
Pearl, J. Causality: Models, Reasoning and Inference . Cambridge University Press, USA, 2nd
edition, 2009. ISBN 052189560X.
Petroni, F., Rockt¨aschel, T., Riedel, S., Lewis, P., Bakhtin, A., Wu, Y ., and Miller, A. Language
models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP), pp. 2463–2473, Hong Kong, China, November 2019. Association
for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://aclanthology.
org/D19-1250.
Petroni, F., Lewis, P., Piktus, A., Rockt¨aschel, T., Wu, Y ., Miller, A. H., and Riedel, S. How context
affects language models’ factual predictions. In Automated Knowledge Base Construction, 2020.
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al. Language models are
unsupervised multitask learners. OpenAI blog, pp. 9, 2019.
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., and Liu, P. J.
Exploring the limits of transfer learning with a uniﬁed text-to-text transformer.Journal of Machine
Learning Research, 21(140):1–67, 2020.
Roberts, A., Raffel, C., and Shazeer, N. How much knowledge can you pack into the param-
eters of a language model? In Proceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP) , pp. 5418–5426, Online, November 2020. Associ-
ation for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.437. URL https:
//aclanthology.org/2020.emnlp-main.437.
Sundararajan, M., Taly, A., and Yan, Q. Axiomatic attribution for deep networks. In International
conference on machine learning, pp. 3319–3328. PMLR, 2017.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and
Polosukhin, I. Attention is all you need. In Advances in neural information processing systems, pp.
5998–6008, 2017.
Vig, J., Gehrmann, S., Belinkov, Y ., Qian, S., Nevo, D., Sakenis, S., Huang, J., Singer, Y ., and Shieber,
S. Causal mediation analysis for interpreting neural NLP: The case of gender bias. arXiv preprint
arXiv:2004.12265, 2020a.
Vig, J., Gehrmann, S., Belinkov, Y ., Qian, S., Nevo, D., Singer, Y ., and Shieber, S. M. Investigating
gender bias in language models using causal mediation analysis. In NeurIPS, 2020b.
Wang, B. and Komatsuzaki, A. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.
https://github.com/kingoflolz/mesh-transformer-jax, May 2021.
Zhang, Y ., Galley, M., Gao, J., Gan, Z., Li, X., Brockett, C., and Dolan, W. B. Generating informative
and diverse conversational responses via adversarial information maximization. In NeurIPS, 2018.
Zhao, S., Pascual, D., Brunner, G., and Wattenhofer, R. Of non-linearity and commutativity in BERT.
In 2021 International Joint Conference on Neural Networks (IJCNN), pp. 1–8. IEEE, 2021.
Zhong, Z., Friedman, D., and Chen, D. Factual probing is [MASK]: Learning vs. learning to
recall. In Proceedings of the 2021 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies , pp. 5017–5033, Online, June
2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.398. URL
https://aclanthology.org/2021.naacl-main.398.
Zhu, C., Rawat, A. S., Zaheer, M., Bhojanapalli, S., Li, D., Yu, F., and Kumar, S. Modifying
memories in transformer models. arXiv preprint arXiv:2012.00363, 2020.
13
Appendices
A Solving for Λ Algebraically
Here we present the detailed derivation of Eqn. 2, including the linear system that is used to calculate
Λ fromv∗,C, andk∗. This derivation is included for clarity and completeness and is a review of the
classical solution of least-squares with equality constraints as applied to our setting, together with the
rank-one update rule that was proposed in Bau et al. (2020).
We assume thatW is the optimal least-squares solution for memorizing a mapping from a previous
set of keysK to valuesV ; this solution can be written using the normal equations as follows.
theW that minimizes ||WK−V||2
F (5)
solves WKK T =VK T (6)
Here the Frobenius norm is used to write the total square error since the variable being optimized is a
matrixW rather than a vectorx as in the classical textbook presentation of least squares.
We wish to ﬁnd a new matrix ˆW that solves the same least squares problem with an additional
equality constraint as written in Eqn. 2:
ˆWk∗ =v∗ (7)
This is the well-studied problem of least squares with a linear equality constraint. The direct solution
can be derived by deﬁning and minimizing a Lagrangian, whereΛ∈ RH minimizes the following:
deﬁne L( ˆW, Λ) = 1
2|| ˆWK−V||2
F− ΛT ( ˆWk∗−v∗) (8)
= 1
2( ˆWK )( ˆWK )T−V ( ˆWK )T + 1
2VV T− ΛT ( ˆWk∗−v∗) (9)
setting 0 = ∂L
∂ ˆW
= ˆW (KK T )−VK T− ΛkT
∗ (10)
ˆWKK T =VK T + ΛkT
∗ (11)
Subtracting Eqn. 6 from Eqn. 11, most terms cancel, and we obtain the update rule:
( ˆW−W )KK T = ΛkT
∗ (12)
ˆW =W + Λ(C−1k∗)T (13)
The last step is obtained by deﬁningC =KK T , assumingC is nondegenerate, and exploiting the
symmetry ofC. Here we also write the row vector term asuT = (C−1k∗)T∈ RD, so we can write
simply (rearranging Eqn. 2 and Eqn. 13):
ˆWI− ΛuT =W (14)
To solve for Λ, we note that Eqn. 14 and Eqn. 7 form a linear system that allows both ˆW and Λ to be
solved simultaneously if written together in block form.

 ˆW Λ




I k∗
−uT 0

 =
[
W v∗
]
(15)
That is equivalent to substituting Eqn. 13 into Eqn. 7 and calculating the following:
ˆWk∗ = (W + ΛuT )k∗ =Wk∗ + Λ(uTk∗) =v∗ (16)
Λ = v∗−Wk∗
uTk∗
= v∗−Wk∗
(C−1k∗)Tk∗
(17)
14
B Causal Tracing
B.1 Experimental Settings
Note that, in by-layer experimental results, layers are numbered from 0 toL− 1 rather than 1 toL.
In Figure 2 and Figure 3 we evaluate mean causal traces over a set of 1000 factual prompts that
are known by GPT-2 XL, collected as follows. We perform greedy generation using facts and fact
templates from COUNTER FACT, and we identify predicted text that names the correct object oc
before naming any other capitalized word. We use the text up to but not including the objectoc as the
prompt, and we randomly sample 1000 of these texts. In this sample of known facts, the predicted
probability of the correct object token calculated by GPT-2 XL averages 27.0%.
In the corrupted run, we corrupt the embeddings of the token naming the subjects by adding Gaussian
noiseϵ∼N (0;ν), whereν = 3σt is set to be three times larger than the observed standard deviation
σt of token embeddings as sampled over a body of text. For each run of text, the process is repeated
ten times with different samples of corruption noise. On average, this reduces the correct object token
score to 8.47%, less than one third the original score.
When we restore hidden states from the original run, we substitute the originally calculated values
from the same layer and the same token, and then we allow subsequent calculations to proceed
without further intervention. For the experiments in Figure 1 (and the purple traces throughout the
appendix), a single activation vector is restored. Naturally, restoring the last vector on the last token
will fully restore the original predicted scores, but our plotted results show that there are also earlier
activation vectors at a second location that also have a strong causal effect: the average maximum
score seen by restoring the most impactful activation vector at the last token of the subject is 19.5%.
In Figure 1j where effects are bucketed by layer, the maximum effect is seen around the 15th layer of
the last subject token, where the score is raised on average to 15.0%.
B.2 Separating MLP and Attn Effects
When decomposing the effects into MLP and Attn lookups, we found that restoring single activation
vectors from individual MLP and individual Attn lookups had generally negligible effects, suggesting
the decisive information is accumulated across layers. Therefore for MLP and Attn lookups, we
restored runs of ten values of m(l)
i (anda(l)
i , respectively) for an interval of layers ranging from
[l∗− 4,...,l∗ + 5] (clipping at the edges), where the results are plotted at layerl∗. In an individual
text, we typically ﬁnd some run of MLP lookups that nearly restores the original prediction value,
with an average maximum score of 23.6%. Figure 2b buckets averages for each token-location pair,
and ﬁnds the maximum effect at an interval at the last entity token, centered at the the 17th layer,
which restores scores to an average of 15.0%. For Attn lookups (Figure 2c), the average maximum
score over any location is 19.4%, and when bucketed by location, the maximum effect is centered at
the 32nd layer at the last word before prediction, which restores scores to an average of 16.5%.
Figure 7 shows mean causal traces as line plots with 95% conﬁdence intervals, instead of heatmaps.
(a) (b) (c)
GPT-2 XL
Figure 7: Mean causal traces of GPT-XL over a sample of 1000 factual statements, shown as a line plot with
95% conﬁdence intervals. (a) Shows the same data as Figure 1j as a line plot instead of a heatmap; (b) matches
Figure 1k; (c) matches Figure 1m. The conﬁdence intervals conﬁrm that the distinctions between peak and
non-peak causal effects at both early and late sites are signiﬁcant.
15