Published as a conference paper at ICLR 2023
Michael
Jordan
now
plays
ğ‘˜!
"ğ‘Š!"
# ğ‘Š$%&
#
attn!
ğ‘Š"#$! stores ğ‘˜%
! â†’ ğ‘š %
! pairs minimizing:
!
!"#
$
ğ‘Š%&'
( ğ‘˜!
( âˆ’ ğ‘š !
( )
key for subject memorized value
attn module vector state
direct path
mlp module
mlp critical path
non-mediating components
information moved by attention
(a)
(b)
(c)
ğ‘š!
"
ğ‘!
"
â„!
"
(d)
range of critical MLP layers â„›
last
subject
token ğ‘†
Figure 2: MEMIT modifies transformer parameters on the critical path of MLP-mediated factual recall.
We edit stored associations based on observed patterns of causal mediation: (a) first, the early-layer attention
modules gather subject names into vector representations at the last subject token S. (b) Then MLPs at layers
l âˆˆ R read these encodings and add memories to the residual stream. (c) Those hidden states are read by
attention to produce the output. (d) MEMIT edits memories by storing vector associations in the critical MLPs.
confirm that GPT-J has a concentration of mediating states hl
i; moreover, they highlight a mediating
causal role for a range of MLP modules, which can be seen as a large gap between the effect of single
states (purple bars in Figure 3) and the effects with MLP severed (green bars); this gap diminishes
after layer 8. Unlike Meng et al. (2022) who use this test to identify a single edit layer, we select the
whole range of critical MLP layers l âˆˆ R. For GPT-J, we have R = {3, 4, 5, 6, 7, 8}.
0
 5
 10
 15
 20
 25
Layer at which hidden state is restored
0.0%
5.0%
10.0%Average Indirect Effect
Causal effect of hidden states Attn or MLP modules severed
Effect of single state
Effect w/ Attn severed
Effect w/ MLP severed
Figure 3: A critical mediating role for mid-layer MLPs.
Given that a range of MLPs play a joint
mediating role in recalling facts, we ask:
what is the role of one MLP in stor-
ing a memory? Each token state in a
transformer is part of the residual stream
that all attention and MLP modules read
from and write to (Elhage et al., 2021).
Unrolling Eqn. 2 for hL
i = hL
[S](pi):
hL
i = h0
i +
LX
l=1
al
i +
LX
l=1
ml
i. (6)
Eqn. 6 highlights that each individual
MLP contributes by adding to the memory at hL
i (Figure 2b), which is later read by last-token
attention modules (Figure 2c). Therefore, when writing new memories into G, we can spread the
desired changes across all the critical layers ml
i for l âˆˆ R.
4.2 B ATCH UPDATE FOR A SINGLE LINEAR ASSOCIATIVE MEMORY
In each individual layer l, we wish to store a large batch of u â‰« 1 memories. This section derives an
optimal single-layer update that minimizes the squared error of memorized associations, assuming
that the layer contains previously-stored memories that should be preserved. We denote W0 â‰œ W l
out
(Eqn. 4, Figure 2) and analyze it as a linear associative memory (Kohonen, 1972; Anderson, 1972)
that associates a set of input keys ki â‰œ kl
i (encoding subjects) to corresponding memory values
mi â‰œ ml
i (encoding memorized properties) with minimal squared error:
W0 â‰œ argmin
Ë†W
nX
i=1
 Ë†W ki âˆ’ mi

2
. (7)
If we stack keys and memories as matrices K0 = [k1 | k2 | Â· Â· Â· | kn] and M0 = [m1 | m2 | Â· Â· Â· | mn],
then Eqn. 7 can be optimized by solving the normal equation (Strang, 1993, Chapter 4):
W0K0K T
0 = M0K T
0 . (8)
Suppose that pre-training sets a transformer MLPâ€™s weights to the optimal solutionW0 as defined in
Eqn. 8. Our goal is to update W0 with some small change âˆ† that produces a new matrix W1 with
4
Published as a conference paper at ICLR 2023
ğ‘§!
â„!
"
ğ‘˜!
"#$
ğ‘š!
"#$ğ‘Š!%
"#$ ğ‘Š&'("#$
attn!"#
â„!
"#)
ğ‘˜!
"#*
ğ‘š!
"#*ğ‘Š!%
"#* ğ‘Š&'("#*
attn!"$
â„!
"#$
ğ‘˜!
" ğ‘š!
"ğ‘Š!%
" ğ‘Š&'("
attn!
â„!
"#*
(i) For each memory ğ‘–, find ğ‘§! by optimizing Eqn. 16
(ii-a) Add âˆ†"#$ s.t. âˆ€ğ‘–: ğ‘š !
"#$ += +!# ,!
"
)
Re-collect layer ğ¿ âˆ’ 1 activations
(ii-b) Add âˆ†"#* s.t. âˆ€ğ‘–: ğ‘š !
"#* += +!# ,!
"
$ (ii-c) Add âˆ†" s.t. âˆ€ğ‘–: ğ‘š !
" += +!# ,!
"
*
Re-collect layer ğ¿ activations
(ii) For each layer ğ‘™, apply updates using
Eqn. 14 to move all â„!
" towards ğ‘§!
All states examined at ğ‘† = Last subject token for ğ‘!
Figure 4: The MEMIT update. We first (i) replace hl
i with the vector zi and optimize Eqn. 16 so that it
conveys the new memory. Then, after all zi are calculated we (ii) iteratively insert a fraction of the residuals
for all zi over the range of critical MLP modules, executing each layerâ€™s update by applying Eqn. 14. Because
changing one layer will affect activations of downstream modules, we recollect activations after each iteration.
a set of additional associations. Unlike Meng et al. (2022), we cannot solve our problem with a
constraint that adds only a single new association, so we define an expanded objective:
W1 â‰œ argmin
Ë†W
 nX
i=1
 Ë†W ki âˆ’ mi

2
+
n+uX
i=n+1
 Ë†W ki âˆ’ mi

2
!
. (9)
We can solve Eqn. 9 by again applying the normal equation, now written in block form:
W1 [K0 K1] [K0 K1]T = [M0 M1] [K0 K1]T (10)
which expands to: (W0 + âˆ†)(K0K T
0 + K1K T
1 ) = M0K T
0 + M1K T
1 (11)
W0K0K T
0 + W0K1K T
1 + âˆ†K0K T
0 + âˆ†K1K T
1 = M0K T
0 + M1K T
1 (12)
subtracting Eqn. 8 from Eqn. 12 : âˆ†(K0K T
0 + K1K T
1 ) = M1K T
1 âˆ’ W0K1K T
1 . (13)
A succinct solution can be written by defining two additional quantities: C0 â‰œ K0K T
0 , a constant
proportional to the uncentered covariance of the pre-existing keys, andR â‰œ M1 âˆ’ W0K1, the residual
error of the new associations when evaluated on old weights W0. Then Eqn. 13 can be simplified as:
âˆ† = RK T
1 (C0 + K1K T
1 )âˆ’1. (14)
Since pretraining is opaque, we do not have access to K0 or M0. Fortunately, computing Eqn. 14
only requires an aggregate statistic C0 over the previously stored keys. We assume that the set of
previously memorized keys can be modeled as a random sample of inputs, so that we can compute
C0 = Î» Â· Ek

kkT
(15)
by estimating Ek

kkT
, an uncentered covariance statistic collected using an empirical sample of
vector inputs to the layer. We must also select Î», a hyperparameter that balances the weighting of
new v.s. old associations; a typical value is Î» = 1.5 Ã— 104.
4.3 U PDATING MULTIPLE LAYERS
We now define the overall update algorithm (Figure 4). Inspired by the observation that robustness is
improved when parameter change magnitudes are minimized (Zhu et al., 2020), we spread updates
evenly over the range of mediating layers R. We define a target layer L â‰œ max(R) at the end of
the mediating layers, at which the new memories should be fully represented. Then, for each edit
(si, ri, oi) âˆˆ E , we (i) compute a hidden vector zi to replace hL
i such that adding Î´i â‰œ zi âˆ’ hL
i to the
hidden state at layer L and token T will completely convey the new memory. Finally, one layer at a
time, we (ii) modify the MLP at layer l, so that it contributes an approximately-equal portion of the
change Î´i for each memory i.
(i) Computing zi. For the ith memory, we first compute a vectorzi that would encode the association
(si, ri, oi) if it were to replace hL
i at layer L at token S. We find zi = hL
i + Î´i by optimizing the
residual vector Î´i using gradient descent:
zi = hL
i + argmin
Î´i
1
P
PX
j=1
âˆ’ log PG(hL
i +=Î´i) [oi | xj âŠ• p(si, ri)] . (16)
5
Published as a conference paper at ICLR 2023
In words, we optimize Î´i to maximize the modelâ€™s prediction of the desired objectoi, given a set of
factual prompts {xj âŠ• p(si, ri)} that concatenate random prefixes xj to a templated prompt to aid
generalization across contexts. G(hL
i += Î´i) indicates that we modify the transformer execution by
substituting the modified hidden state zi for hL
i ; this is called â€œhookingâ€ in popular ML libraries.
(ii) Spreading zi âˆ’ hL
i over layers. We seek delta matrices âˆ†l such that:
setting Ë†W l
out := W l
out + âˆ†l for all l âˆˆ R optimizes min
{âˆ†l}
X
i
zi âˆ’ Ë†hL
i

2
, (17)
where Ë†hL
i = h0
i +
LX
l=1
al
i +
LX
l=1
Ë†W l
out Ïƒ
 
W l
inÎ³
 
hlâˆ’1
t

. (18)
Because edits to any layer will influence all following layersâ€™ activations, we calculateâˆ†l iteratively
in ascending layer order (Figure 4ii-a,b,c). To compute each individualâˆ†l, we need the corresponding
keys K l = [kl
1 | Â· Â· Â· | kl
n] and memories M l = [ml
1 | Â· Â· Â· | ml
n] to insert using Eqn. 14. Each key kl
i
is computed as the input to W l
out at each layer l (Figure 2d):
kl
i = 1
P
PX
j=1
k(xj + si), where k(x) = Ïƒ
 
W l
in Î³
 
hlâˆ’1
i (x)

. (19)
ml
i is then computed as the sum of its current value and a fraction of the remaining top-level residual:
ml
i = Woutkl
i + rl
i where rl
i is the residual given by zi âˆ’ hL
i
L âˆ’ l + 1, (20)
where the denominator of ri spreads the residual out evenly. Algorithm 1 summarizes MEMIT, and
additional implementation details are offered in Appendix B.
Algorithm 1:The MEMIT Algorithm
Data:Requested editsE = {(si, ri, oi)}, generatorG, layers to editS, covariancesCl
Result:Modified generator containing edits fromE
1 forsi, ri, oi âˆˆ E do // Compute targetzi vectors for every memoryi
2 optimizeÎ´i â† argminÎ´i
1
P
PP
j=1âˆ’logPG(hL
i +=Î´i) [oi | xj âŠ• p(si, ri)] (Eqn. 16)
3 zi â† hL
i + Î´i
4 end
5 forl âˆˆ Rdo // Perform update: spread changes over layers
6 hl
i â† hlâˆ’1
i + al
i + ml
i (Eqn. 2) // Run layerl with updated weights
7 forsi, ri, oi âˆˆ E do
8 kl
i â† kl
i = 1
P
PP
j=1k(xj + si) (Eqn. 19)
9 rl
i â† ziâˆ’hL
i
Lâˆ’l+1 (Eqn. 20) // Distribute residual over remaining layers
10 end
11 Kl â† [kl1
i , ..., kL
i ]
12 Rl â† [rl1
i , ..., rL
i ]
13 âˆ†l â† RlKlT(Cl + KlKlT)âˆ’1 (Eqn. 14)
14 Wl â† Wl + âˆ†l // Update layerl MLP weights in model
15 end
5 E XPERIMENTS
5.1 M ODELS AND BASELINES
We run experiments on two autoregressive LLMs: GPT-J (6B) and GPT-NeoX (20B). For baselines,
we first compare with a naive fine-tuning approach that uses weight decay to prevent forgetfulness
(FT-W). Next, we experiment with MEND, a hypernetwork-based model editing approach that edits
multiple facts at the same time (Mitchell et al., 2021). Finally, we run a sequential version of ROME
(Meng et al., 2022): a direct model editing method that iteratively updates one fact at a time. The
recent SERAC model editor (Mitchell et al., 2022) does not yet have public code, so we cannot
compare with it at this time. See Appendix B for implementation details.
6